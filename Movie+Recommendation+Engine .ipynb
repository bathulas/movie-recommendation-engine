{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset: Movielens\n",
    "# Environment: Apache Spark, Python, AWS EC2 m4.large \n",
    "# Movie recommendation engine built using Collaborative filtering with explicit feedback\n",
    "\n",
    "\n",
    "# Collaborative filtering is commonly used for recommender systems. \n",
    "# These techniques aim to fill in the missing entries of a user-item association matrix. \n",
    "# spark.mllib currently supports model-based collaborative filtering, in which users and products are described by a small set of latent factors that can be used to predict missing entries. \n",
    "# spark.mllib uses the alternating least squares (ALS) algorithm to learn these latent factors. \n",
    "# The implementation in spark.mllib has the following parameters:\n",
    "\n",
    "# numBlocks is the number of blocks used to parallelize computation.\n",
    "# rank is the number of latent factors in the model.\n",
    "# iterations is the number of iterations of ALS to run. \n",
    "# ALS typically converges to a reasonable solution in 20 iterations or less.\n",
    "# lambda specifies the regularization parameter in ALS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ratings_raw_data = sc.textFile(\"ml-20m/ratings.csv\")\n",
    "movies_raw_data = sc.textFile(\"ml-20m/movies.csv\")\n",
    "ratings_data_header = ratings_data.take(1)[0]\n",
    "movies_data_header = movies_data.take(1)[0]\n",
    "\n",
    "#creating ratings and movies RDDs and storing the headers in another RDD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'userId,movieId,rating,timestamp'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_raw_data.first()\n",
    "\n",
    "#checking the first line which is the header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ratings_data = ratings_raw_data.filter(lambda line: line!=ratings_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()\n",
    "    \n",
    "# reading the raw ratings data without header, mapping and creating a cached RDD \n",
    "    \n",
    "movies_data = movies_raw_data.filter(lambda line: line!=movies_data_header)\\\n",
    "    .map(lambda line: line.split(\",\")).map(lambda tokens:(tokens[0],tokens[1],tokens[2])).cache()\n",
    "    \n",
    "# reading the raw movies data without header, mapping and creating a cached RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "training_RDD, validation_RDD, test_RDD = ratings_data.randomSplit([6, 2, 2], seed=0L)\n",
    "\n",
    "#create a transformation to split the ratings RDD in to training, validation and test RDDs\n",
    "\n",
    "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "#create a transformation to prepare validation set\n",
    "\n",
    "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "#create a transformation to prepare test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'1', u'2', u'3.5')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_data.first()\n",
    "\n",
    "#action to make sure header is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 3 the RMSE is 0.827672311062\n",
      "For rank 6 the RMSE is 0.814785432209\n",
      "For rank 9 the RMSE is 0.816497886269\n",
      "model with the best rank is 6\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "#import Alternating least squares from pyspark mllib \n",
    "\n",
    "seed = 5L\n",
    "iterations = 8\n",
    "ranks = [3, 6, 9]\n",
    "regularization_parameter = 0.1\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "#set hyperparameter values or ranges\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,lambda_=regularization_parameter)\n",
    "#training the model\n",
    "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda x: ((x[0], x[1]), x[2]))\n",
    "#predicting the results using validation set\n",
    "    rates_and_preds = validation_RDD.map(lambda x: ((int(x[0]), int(x[1])), float(x[2]))).join(predictions)\n",
    "#joining actual ratings and predictions    \n",
    "    error = math.sqrt(rates_and_preds.map(lambda x: (x[1][0] - x[1][1])**2).mean())\n",
    "#calculate the RMSE \n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "\n",
    "    print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print 'model with the best rank is %s' % best_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((18624, 1233), 4.304325179879104),\n",
       " ((18624, 3617), 2.295641218397508),\n",
       " ((18624, 103249), 2.9205323565716235),\n",
       " ((18624, 4545), 2.469724193933608),\n",
       " ((18624, 91306), 3.8818960894869847)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.take(5)\n",
    "\n",
    "#check predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((13690, 1208), (3.0, 3.1904670577022287)),\n",
       " ((106110, 2420), (3.5, 3.727345381968274)),\n",
       " ((62497, 1653), (5.0, 4.092835245815293)),\n",
       " ((75178, 1296), (4.0, 4.105249382340389)),\n",
       " ((117371, 911), (5.0, 3.8284228092195365))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_and_preds.take(5)\n",
    "#compare predictions and actual ratings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For testing data the RMSE is 0.815253154176\n"
     ]
    }
   ],
   "source": [
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "\n",
    "predictions = model.predictAll(test_for_predict_RDD).map(lambda x: ((x[0], x[1]), x[2]))\n",
    "\n",
    "# testing the model using test set \n",
    "\n",
    "rates_and_preds = test_RDD.map(lambda x: ((int(x[0]), int(x[1])), float(x[2]))).join(predictions)\n",
    "\n",
    "#joining actual test set ratings and predictions to compare the results\n",
    "\n",
    "Error = math.sqrt(rates_and_preds.map(lambda x: (x[1][0] - x[1][1])**2).mean())\n",
    "\n",
    "#calculate the RMSE error \n",
    "\n",
    "print 'testing data RMSE is %s' % (Error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 27278 movies in the complete dataset\n"
     ]
    }
   ],
   "source": [
    "\n",
    "complete_movies_titles = movies_data.map(lambda x: ((x[0]),x[1]))\n",
    "    \n",
    "print \"There are %s movies in the complete dataset\" % (complete_movies_titles.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def counts_and_averages(ID_ratings_tuple):\n",
    "    nratings = len(ID_ratings_tuple[1])\n",
    "    return ID_ratings_tuple[0], (nratings, float(sum(float(x) for x in ID_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings_RDD = (ratings_data.map(lambda x: (float(x[1]), x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(counts_and_averages)\n",
    "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(122880.0, (1, 3.0)),\n",
       " (118784.0, (1, 3.5)),\n",
       " (27824.0, (6, 3.5833333333333335)),\n",
       " (16.0, (17394, 3.7874554444061173)),\n",
       " (122480.0, (2, 1.5))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ID_with_avg_ratings_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New user ratings: [(0, 260, 4), (0, 1, 3), (0, 16, 3), (0, 25, 4), (0, 32, 4), (0, 335, 1), (0, 379, 1), (0, 296, 3), (0, 858, 5), (0, 50, 4)]\n"
     ]
    }
   ],
   "source": [
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,260,4), \n",
    "     (0,1,3), \n",
    "     (0,16,3), \n",
    "     (0,25,4), \n",
    "     (0,32,4), \n",
    "     (0,335,1), \n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
    "print 'New user ratings: %s' % new_user_ratings_RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "complete_data_with_new_ratings_RDD = ratings_data.union(new_user_ratings_RDD)\n",
    "\n",
    "# union new users ratings with the original ratings data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model trained in 291.234 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start_time = time()\n",
    "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "total_time = time() - start_time\n",
    "\n",
    "print \"New model trained in %s seconds\" % round(total_time,3)\n",
    "\n",
    "#train the model again with the new data and hyperparameters from the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings)\n",
    "# get new user movie IDs and keep just those not on the ID list \n",
    "new_user_unrated_movies_RDD = (complete_data_with_new_ratings_RDD.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
    "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
    "\n",
    "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
    "\n",
    "\n",
    "new_user_recommendations_rating_title_and_count_RDD.take(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "new_user_recommendations_rating_title_and_count_RDD = \\\n",
    "    new_user_recommendations_rating_title_and_count_RDD.map(lambda x: (x[1][0][1], x[1][0][0], x[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "top_movies = new_user_recommendations_rating_RDD.filter(lambda x: x[0]>=50 ).takeOrdered(25, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 50 reviews):\\n%s' %\n",
    "        '\\n'.join(map(str, top_movies)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=8, product=1208, rating=3.5836688392131775),\n",
       " Rating(user=7, product=500, rating=3.348774159532742)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_movie = sc.parallelize([(8, 1208),(7,500)])\n",
    "individual_movie_rating_RDD = final_model.predictAll(my_movie)\n",
    "individual_movie_rating_RDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "# Save and load model\n",
    "new_ratings_model.save(sc,'~/freecom')\n",
    "final_model = MatrixFactorizationModel.load(sc, '~/freecom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
